# File: cleaner.py
# Responsibility: Reads the raw scraped data (raw_bestsellers.csv), performs
#                 data cleaning and type conversion, and outputs the
#                 clean data (cleaned_bestsellers.csv).

import pandas as pd
import os 
def clean_amazon_data(df):
    """Takes a raw Amazon product DataFrame and performs comprehensive data cleaning and type conversion.

    Args:
        df (pd.DataFrame): The raw DataFrame containing product data, 
                           typically generated by scraper.py.

    Returns:
        pd.DataFrame: A new DataFrame with columns cleaned and converted to 
                      appropriate numeric types.
    """
    cleaned_df = df.copy()

    # Clean Rank: remove '#' character and convert to integer
    if 'Rank' in cleaned_df.columns:
        cleaned_df['Rank'] = pd.to_numeric(
            cleaned_df['Rank'].astype(str).str.replace('#', '', regex=False), 
            errors='coerce'
        ).fillna(0).astype(int)

    # Clean Price: extract numeric part and convert to float
    if 'Price' in cleaned_df.columns:
        cleaned_df['Price'] = pd.to_numeric(
            cleaned_df['Price'].astype(str).str.extract(r'(\d+\.?\d*)')[0], 
            errors='coerce'
        )

    # Clean Review Count: remove commas and convert to integer
    if 'Review Count' in cleaned_df.columns:
        cleaned_df['Review Count'] = pd.to_numeric(
            cleaned_df['Review Count'].astype(str).str.replace(',', '', regex=False),
            errors='coerce'
        ).fillna(0).astype(int)

    # Clean Rating: extract the number before 'out of 5 stars' and convert to float
    if 'Rating' in cleaned_df.columns:
        cleaned_df['Rating'] = pd.to_numeric(
            cleaned_df['Rating'].astype(str).str.split(' ').str[0],
            errors='coerce'
        )
    
    return cleaned_df

def main():
    """The main execution function for the script.
    
    It handles reading the raw CSV, calling the cleaning function, 
    and saving the processed data.
    """
    input_filepath = os.path.join("output", "data", "raw_bestsellers.csv")
    output_filepath = os.path.join("output", "data", "cleaned_bestsellers.csv")
    
    try:
        print(f"Reading raw file: {input_filepath}")
        raw_df = pd.read_csv(input_filepath)
        
        print("\n--- Data info before cleaning ---")
        raw_df.info()

        print("\n--- Starting data cleaning process ---")
        cleaned_df = clean_amazon_data(raw_df)
        print("--- Data cleaning complete ---")

        print("\n--- Data info after cleaning ---")
        cleaned_df.info()
        
        print("\n--- Preview of cleaned data (first 5 rows) ---")
        print(cleaned_df.head())

        cleaned_df.to_csv(output_filepath, index=False, encoding="utf_8_sig") 
        print(f"\nTask complete! Cleaned data saved to {output_filepath}")

    except FileNotFoundError:
        print(f"Error: Input file not found at '{input_filepath}'. Please run scraper.py first.")
    except Exception as e:
        print(f"An unexpected error occurred during processing: {e}")

if __name__ == "__main__":
    main()